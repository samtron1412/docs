# Overview

- https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)
    + Invented in the paper: Attention Is All You Need
        * https://en.wikipedia.org/wiki/Attention_Is_All_You_Need
- https://www.nvidia.com/en-us/glossary/generative-ai/
- A transformer is a deep learning architecture based on the multi-head
  attention mechanism.
- It is notable for not containing any recurrent units, and thus
  requires less training time than previous recurrent neural
  architectures, such as long short-term memory (LSTM).


